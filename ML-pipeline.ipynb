{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (packaging 23.0 (/Users/krishnayogi/ls/envs/myenv_x86/lib/python3.8/site-packages), Requirement.parse('packaging<22.0,>=20.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (packaging 23.0 (/Users/krishnayogi/ls/envs/myenv_x86/lib/python3.8/site-packages), Requirement.parse('packaging<22.0,>=20.0'), {'azureml-core'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (packaging 23.0 (/Users/krishnayogi/ls/envs/myenv_x86/lib/python3.8/site-packages), Requirement.parse('packaging<22.0,>=20.0'), {'azureml-core'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (packaging 23.0 (/Users/krishnayogi/ls/envs/myenv_x86/lib/python3.8/site-packages), Requirement.parse('packaging<22.0,>=20.0'), {'azureml-core'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (packaging 23.0 (/Users/krishnayogi/ls/envs/myenv_x86/lib/python3.8/site-packages), Requirement.parse('packaging<22.0,>=20.0'), {'azureml-core'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (packaging 23.0 (/Users/krishnayogi/ls/envs/myenv_x86/lib/python3.8/site-packages), Requirement.parse('packaging<22.0,>=20.0'), {'azureml-core'}).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from math import sqrt\n",
    "warnings.filterwarnings('ignore')\n",
    "from azureml.core.run import Run\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "subscription_id = '3566c1ea-5752-413c-9cf4-e7e55fca7d8f'\n",
    "resource_group = 'dp100'\n",
    "workspace_name = 'aml'\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = workspace.get_mlflow_tracking_uri()\n",
    "mlflow.set_tracking_uri(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml://southeastasia.api.azureml.ms/mlflow/v2.0/subscriptions/3566c1ea-5752-413c-9cf4-e7e55fca7d8f/resourceGroups/dp100/providers/Microsoft.MachineLearningServices/workspaces/aml?\n"
     ]
    }
   ],
   "source": [
    "print(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"workspaceblobstore\",\n",
      "  \"container_name\": \"azureml-blobstore-6d61d964-6aca-41cd-a070-05ade70b8520\",\n",
      "  \"account_name\": \"aml0148788539\",\n",
      "  \"protocol\": \"https\",\n",
      "  \"endpoint\": \"core.windows.net\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "datastore = workspace.get_default_datastore()\n",
    "print(datastore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None\n"
     ]
    }
   ],
   "source": [
    "# Importing pre-processed dataset\n",
    "dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, 'data/weather_dataset_processed.csv')])\n",
    "\n",
    "#dataset = Dataset.get_by_name(workspace, name='data/weather_dataset_processed.csv')\n",
    "print(dataset.name, dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabularDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'data/weather_dataset_processed.csv')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\",\n",
      "    \"ParseDelimited\",\n",
      "    \"DropColumns\",\n",
      "    \"SetColumnTypes\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_speed_kmph</th>\n",
       "      <th>Wind_bearing_degrees</th>\n",
       "      <th>Visibility_km</th>\n",
       "      <th>Pressure_millibars</th>\n",
       "      <th>Weather_conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-03-31 22:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>9.472222</td>\n",
       "      <td>0.89</td>\n",
       "      <td>14.1197</td>\n",
       "      <td>251</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1015.13</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-03-31 23:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>9.355556</td>\n",
       "      <td>0.86</td>\n",
       "      <td>14.2646</td>\n",
       "      <td>259</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1015.63</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-04-01 00:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>9.377778</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3.9284</td>\n",
       "      <td>204</td>\n",
       "      <td>14.9569</td>\n",
       "      <td>1015.94</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-04-01 01:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.288889</td>\n",
       "      <td>0.83</td>\n",
       "      <td>14.1036</td>\n",
       "      <td>269</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1016.41</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-04-01 02:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.755556</td>\n",
       "      <td>0.83</td>\n",
       "      <td>11.0446</td>\n",
       "      <td>259</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1016.51</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp                Location  Temperature_C  Humidity  \\\n",
       "0 2006-03-31 22:00:00  Port of Turku, Finland       9.472222      0.89   \n",
       "1 2006-03-31 23:00:00  Port of Turku, Finland       9.355556      0.86   \n",
       "2 2006-04-01 00:00:00  Port of Turku, Finland       9.377778      0.89   \n",
       "3 2006-04-01 01:00:00  Port of Turku, Finland       8.288889      0.83   \n",
       "4 2006-04-01 02:00:00  Port of Turku, Finland       8.755556      0.83   \n",
       "\n",
       "   Wind_speed_kmph  Wind_bearing_degrees  Visibility_km  Pressure_millibars  \\\n",
       "0          14.1197                   251        15.8263             1015.13   \n",
       "1          14.2646                   259        15.8263             1015.63   \n",
       "2           3.9284                   204        14.9569             1015.94   \n",
       "3          14.1036                   269        15.8263             1016.41   \n",
       "4          11.0446                   259        15.8263             1016.51   \n",
       "\n",
       "  Weather_conditions  \n",
       "0               rain  \n",
       "1               rain  \n",
       "2               rain  \n",
       "3               rain  \n",
       "4               rain  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting Pre-Processed data into Training and Validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set is used later to evaluate model performance post training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = df.iloc[:77160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77160, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = df.drop(df_training.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19293, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registering Training and Validation data to the datastore on the workspace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: Data: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.to_csv('Data/training_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation.to_csv('Data/validation_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = workspace.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"Datastore.upload\" is deprecated after version 1.0.69. Please use \"Dataset.File.upload_directory\" to upload your files             from a local directory and create FileDataset in single method call. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 2 files\n",
      "Target already exists. Skipping upload for data/training_data.csv\n",
      "Target already exists. Skipping upload for data/validation_data.csv\n",
      "Uploaded 0 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_7dea0446f077421e809b31a81dfddbb3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datastore.upload(src_dir='Data', target_path='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = Dataset.Tabular.from_delimited_files(datastore.path('data/training_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = Dataset.Tabular.from_delimited_files(datastore.path('data/validation_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = training_dataset.register(workspace=workspace,\n",
    "                                 name='training_dataset',\n",
    "                                 description='Dataset to use for ML training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_ds = validation_dataset.register(workspace=workspace,\n",
    "                                 name='validation_dataset',\n",
    "                                 description='Dataset for validation ML models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data ingestion step - Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_dataset 1\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.get_by_name(workspace, name='training_dataset')\n",
    "print(dataset.name, dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_speed_kmph</th>\n",
       "      <th>Wind_bearing_degrees</th>\n",
       "      <th>Visibility_km</th>\n",
       "      <th>Pressure_millibars</th>\n",
       "      <th>Weather_conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-03-31 22:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>9.472222</td>\n",
       "      <td>0.89</td>\n",
       "      <td>14.1197</td>\n",
       "      <td>251</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1015.13</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-03-31 23:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>9.355556</td>\n",
       "      <td>0.86</td>\n",
       "      <td>14.2646</td>\n",
       "      <td>259</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1015.63</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-04-01 00:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>9.377778</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3.9284</td>\n",
       "      <td>204</td>\n",
       "      <td>14.9569</td>\n",
       "      <td>1015.94</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-04-01 01:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.288889</td>\n",
       "      <td>0.83</td>\n",
       "      <td>14.1036</td>\n",
       "      <td>269</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1016.41</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-04-01 02:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.755556</td>\n",
       "      <td>0.83</td>\n",
       "      <td>11.0446</td>\n",
       "      <td>259</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1016.51</td>\n",
       "      <td>rain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp                Location  Temperature_C  Humidity  \\\n",
       "0 2006-03-31 22:00:00  Port of Turku, Finland       9.472222      0.89   \n",
       "1 2006-03-31 23:00:00  Port of Turku, Finland       9.355556      0.86   \n",
       "2 2006-04-01 00:00:00  Port of Turku, Finland       9.377778      0.89   \n",
       "3 2006-04-01 01:00:00  Port of Turku, Finland       8.288889      0.83   \n",
       "4 2006-04-01 02:00:00  Port of Turku, Finland       8.755556      0.83   \n",
       "\n",
       "   Wind_speed_kmph  Wind_bearing_degrees  Visibility_km  Pressure_millibars  \\\n",
       "0          14.1197                   251        15.8263             1015.13   \n",
       "1          14.2646                   259        15.8263             1015.63   \n",
       "2           3.9284                   204        14.9569             1015.94   \n",
       "3          14.1036                   269        15.8263             1016.41   \n",
       "4          11.0446                   259        15.8263             1016.51   \n",
       "\n",
       "  Weather_conditions  \n",
       "0               rain  \n",
       "1               rain  \n",
       "2               rain  \n",
       "3               rain  \n",
       "4               rain  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77160, 9)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rain', 'rain', 'rain', ..., 'rain', 'rain', 'rain'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['Temperature_C', 'Humidity', 'Wind_speed_kmph', 'Wind_bearing_degrees', 'Visibility_km', 'Pressure_millibars']].values\n",
    "y = df['Weather_conditions'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Training dataset into Train and Test set for ML training\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StandardScaler' from 'sklearn.preprocessing' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_x/15zkvlz965jbcyj2tvmx0ww80000gn/T/ipykernel_1125/2994248865.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'StandardScaler' from 'sklearn.preprocessing' (unknown location)"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and Testing Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/17 17:02:05 INFO mlflow.tracking.fluent: Experiment with name 'mlflow-support-vector-machine' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='', creation_time=1673955125857, experiment_id='34f93cbc-9288-4731-b22a-59b53ef3664b', last_update_time=None, lifecycle_stage='active', name='mlflow-support-vector-machine', tags={}>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myexperiment = Experiment(workspace, \"support-vector-machine\")\n",
    "mlflow.set_experiment(\"mlflow-support-vector-machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVC\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_dataset 1\n"
     ]
    }
   ],
   "source": [
    "print(dataset.name,dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a run in Azureml and mlflow experiments\n",
    "run = myexperiment.start_logging()\n",
    "mlflow.start_run()\n",
    "\n",
    "\n",
    "run.log(\"dataset name\", dataset.name)\n",
    "run.log(\"dataset Version\", dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_grid = GridSearchCV(svc, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 1.41 s, total: 1min 14s\n",
      "Wall time: 1min 16s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 10], &#x27;kernel&#x27;: (&#x27;linear&#x27;, &#x27;rbf&#x27;)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 10], &#x27;kernel&#x27;: (&#x27;linear&#x27;, &#x27;rbf&#x27;)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svc_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': None,\n",
       " 'error_score': nan,\n",
       " 'estimator__C': 1.0,\n",
       " 'estimator__break_ties': False,\n",
       " 'estimator__cache_size': 200,\n",
       " 'estimator__class_weight': None,\n",
       " 'estimator__coef0': 0.0,\n",
       " 'estimator__decision_function_shape': 'ovr',\n",
       " 'estimator__degree': 3,\n",
       " 'estimator__gamma': 'scale',\n",
       " 'estimator__kernel': 'rbf',\n",
       " 'estimator__max_iter': -1,\n",
       " 'estimator__probability': False,\n",
       " 'estimator__random_state': None,\n",
       " 'estimator__shrinking': True,\n",
       " 'estimator__tol': 0.001,\n",
       " 'estimator__verbose': False,\n",
       " 'estimator': SVC(),\n",
       " 'n_jobs': None,\n",
       " 'param_grid': {'kernel': ('linear', 'rbf'), 'C': [1, 10]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_grid.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=svc_grid.get_params(deep=True)['estimator__C'], kernel=svc_grid.get_params(deep=True)['estimator__kernel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging training parameters to AzureML and MLFlow experiments\n",
    "run.log(\"C\", svc_grid.get_params(deep=True)['estimator__C'])\n",
    "run.log(\"Kernel\", svc_grid.get_params(deep=True)['estimator__kernel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_svc = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, predicted_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fscore = f1_score(y_test, predicted_svc, average=\"macro\")\n",
    "precision = precision_score(y_test, predicted_svc, average=\"macro\")\n",
    "recall = recall_score(y_test, predicted_svc, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "repo = git.Repo(search_parent_directories=True)\n",
    "sha = repo.head.object.hexsha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<git.repo.base.Repo '/Users/krishnayogi/myenv_x86/EngineeringMLOps/.git'> b8de9f7e85131e5784b9275da413462a4c750a8b\n"
     ]
    }
   ],
   "source": [
    "print(repo, sha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log to AzureML and MLflow\n",
    "run.log(\"Test_accuracy\", acc)\n",
    "run.log(\"Precision\", precision)\n",
    "run.log(\"Recall\", recall)\n",
    "run.log(\"F-Score\", fscore)\n",
    "run.log(\"Git-sha\", sha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: 4b7a7286-cc74-4c14-8e4f-a7f8934732b5\n"
     ]
    }
   ],
   "source": [
    "run.complete()\n",
    "print (\"run id:\", run.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset name': 'training_dataset',\n",
       " 'dataset Version': 1,\n",
       " 'C': 1.0,\n",
       " 'Kernel': 'rbf',\n",
       " 'Test_accuracy': 0.9916407465007776,\n",
       " 'Precision': 0.9736206238419904,\n",
       " 'Recall': 0.987824315716418,\n",
       " 'F-Score': 0.9805771293084771,\n",
       " 'Git-sha': 'b8de9f7e85131e5784b9275da413462a4c750a8b'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '/subscriptions/3566c1ea-5752-413c-9cf4-e7e55fca7d8f/resourceGroups/dp100/providers/Microsoft.MachineLearningServices/workspaces/aml',\n",
       " 'name': 'aml',\n",
       " 'identity': {'principal_id': '20706030-2cbf-4a0e-8263-49c779061f9f',\n",
       "  'tenant_id': 'f2ef5e7d-a841-46c8-85c1-056389d5dda3',\n",
       "  'type': 'SystemAssigned'},\n",
       " 'location': 'southeastasia',\n",
       " 'type': 'Microsoft.MachineLearningServices/workspaces',\n",
       " 'tags': {},\n",
       " 'sku': 'Basic',\n",
       " 'workspaceid': '6d61d964-6aca-41cd-a070-05ade70b8520',\n",
       " 'sdkTelemetryAppInsightsKey': 'c59896f9-68fe-4b35-bb22-2f0e798a3858',\n",
       " 'description': '',\n",
       " 'friendlyName': 'aml',\n",
       " 'containerRegistry': '/subscriptions/3566c1ea-5752-413c-9cf4-e7e55fca7d8f/resourceGroups/dp100/providers/Microsoft.ContainerRegistry/registries/6d61d9646aca41cda07005ade70b8520',\n",
       " 'keyVault': '/subscriptions/3566c1ea-5752-413c-9cf4-e7e55fca7d8f/resourceGroups/dp100/providers/Microsoft.Keyvault/vaults/aml4325789331',\n",
       " 'applicationInsights': '/subscriptions/3566c1ea-5752-413c-9cf4-e7e55fca7d8f/resourceGroups/dp100/providers/Microsoft.insights/components/aml5324427756',\n",
       " 'storageAccount': '/subscriptions/3566c1ea-5752-413c-9cf4-e7e55fca7d8f/resourceGroups/dp100/providers/Microsoft.Storage/storageAccounts/aml0148788539',\n",
       " 'hbiWorkspace': False,\n",
       " 'provisioningState': 'Succeeded',\n",
       " 'discoveryUrl': 'https://southeastasia.api.azureml.ms/discovery',\n",
       " 'notebookInfo': {'fqdn': 'ml-aml-southeastasia-6d61d964-6aca-41cd-a070-05ade70b8520.southeastasia.notebooks.azure.net',\n",
       "  'resource_id': 'd1f2b8f30d374179981c429be1c48f38'},\n",
       " 'v1LegacyMode': False}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/17 17:53:01 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /var/folders/_x/15zkvlz965jbcyj2tvmx0ww80000gn/T/tmpc5yopagy/model/model.pkl, flavor: sklearn), fall back to return ['scikit-learn==1.2.0', 'cloudpickle==2.2.0']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x7fc5cff90430>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow.sklearn\n",
    "mlflow.sklearn.log_model(svc, 'outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/17 17:53:11 INFO mlflow.tracking.fluent: Experiment with name 'mlflow-random-forest-classifier' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='', creation_time=1673958192313, experiment_id='853e38c0-70c1-47e1-bc0e-de2c48b86200', last_update_time=None, lifecycle_stage='active', name='mlflow-random-forest-classifier', tags={}>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myexperiment = Experiment(workspace, \"random-forest-classifier\")\n",
    "mlflow.set_experiment(\"mlflow-random-forest-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=10, random_state=0, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Run with UUID 09a9fee8-b710-4be0-ace5-69392c4248a6 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_x/15zkvlz965jbcyj2tvmx0ww80000gn/T/ipykernel_30147/2001984768.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# initialize runs in Azureml and mlflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ls/envs/myenv_x86/lib/python3.8/site-packages/mlflow/tracking/fluent.py\u001b[0m in \u001b[0;36mstart_run\u001b[0;34m(run_id, experiment_id, run_name, nested, tags, description)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0mexperiment_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mexperiment_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_active_run_stack\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnested\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         raise Exception(\n\u001b[0m\u001b[1;32m    271\u001b[0m             (\n\u001b[1;32m    272\u001b[0m                 \u001b[0;34m\"Run with UUID {} is already active. To start a new run, first end the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Run with UUID 09a9fee8-b710-4be0-ace5-69392c4248a6 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
     ]
    }
   ],
   "source": [
    "# initialize runs in Azureml and mlflow\n",
    "run = myexperiment.start_logging()\n",
    "mlflow.start_run()\n",
    "\n",
    "\n",
    "# Log dataset used \n",
    "run.log(\"dataset name\", dataset.name)\n",
    "run.log(\"dataset Version\", dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.78 s, sys: 29 ms, total: 1.81 s\n",
      "Wall time: 1.87 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# now you can save it to a file\n",
    "with open('outputs/rf.pkl', 'wb') as f:\n",
    "    pickle.dump(rf, f)\n",
    "\n",
    "\n",
    "    \n",
    "# saving  svc\n",
    "\n",
    "with open('outputs/svc.pkl', 'wb') as f:\n",
    "    pickle.dump(svc, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/krishnayogi/myenv_x86/EngineeringMLOps/04_ML_Pipelines\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#!conda update --all -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_x/15zkvlz965jbcyj2tvmx0ww80000gn/T/ipykernel_5655/781631444.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# and later you can load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'outputs/rf.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# and later you can load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# and later you can load it\n",
    "with open('outputs/rf.pkl', 'rb') as f:\n",
    "    rf = pickle.load(f)\n",
    "    \n",
    "# and later you can load it\n",
    "with open('outputs/svc.pkl', 'rb') as f:\n",
    "    svc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.2.0-cp38-cp38-macosx_10_9_x86_64.whl (8.9 MB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/krishnayogi/ls/envs/myenv_x86/lib/python3.8/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/krishnayogi/ls/envs/myenv_x86/lib/python3.8/site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/krishnayogi/ls/envs/myenv_x86/lib/python3.8/site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/krishnayogi/ls/envs/myenv_x86/lib/python3.8/site-packages (from scikit-learn) (3.1.0)\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/Users/krishnayogi/ls/envs/myenv_x86/lib/python3.8/site-packages/numpy-1.24.1.dist-info/METADATA'\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!python3 -m pip install scikit-learn\n",
    "#!pip3 install --user scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mData\u001b[m\u001b[m              \u001b[34moutputs\u001b[m\u001b[m           svc.pkl\r\n",
      "ML-pipeline.ipynb rf.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging training parameters to AzureML and MLFlow experiments\n",
    "run.log(\"max_depth\", 10)\n",
    "run.log(\"random_state\", 0)\n",
    "run.log(\"n_estimators\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, predicted_rf)\n",
    "fscore = f1_score(y_test, predicted_rf, average=\"macro\")\n",
    "precision = precision_score(y_test, predicted_rf, average=\"macro\")\n",
    "recall = recall_score(y_test, predicted_rf, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log(\"Test_accuracy\", acc)\n",
    "run.log(\"Precision\", precision)\n",
    "run.log(\"Recall\", recall)\n",
    "run.log(\"F-Score\", fscore)\n",
    "run.log(\"Git-sha\", sha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: 8ae01f8c-88c1-430e-b88b-0d1b466c8522\n"
     ]
    }
   ],
   "source": [
    "run.complete()\n",
    "print (\"run id:\", run.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'random_state': 0,\n",
       " 'n_estimators': 100,\n",
       " 'Test_accuracy': 1.0,\n",
       " 'Precision': 1.0,\n",
       " 'Recall': 1.0,\n",
       " 'F-Score': 1.0,\n",
       " 'Git-sha': 'b8de9f7e85131e5784b9275da413462a4c750a8b'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.23.5'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_is_pairwise' from 'sklearn.base' (/Users/krishnayogi/ls/envs/myenv_x86/lib/python3.8/site-packages/sklearn/base.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_x/15zkvlz965jbcyj2tvmx0ww80000gn/T/ipykernel_30147/3201231971.py\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnxruntime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInferenceSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskl2onnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_sklearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_onnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap_as_onnx_mixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskl2onnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_types\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFloatTensorType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskl2onnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgebra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOnnxSub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOnnxDiv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ls/envs/myenv_x86/lib/python3.8/site-packages/skl2onnx/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_sklearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_onnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap_as_onnx_mixin\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m from ._supported_operators import (  # noqa\n\u001b[1;32m     17\u001b[0m     \u001b[0mupdate_registered_converter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_model_alias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ls/envs/myenv_x86/lib/python3.8/site-packages/skl2onnx/convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_topology\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_topology\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils_sklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_process_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_parse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_sklearn_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Invoke the registration of all our converters and shape calculators.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ls/envs/myenv_x86/lib/python3.8/site-packages/skl2onnx/_parse.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m from sklearn.ensemble import (\n\u001b[1;32m     17\u001b[0m     IsolationForest, RandomTreesEmbedding, RandomForestClassifier)\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_process\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianProcessRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBayesianRidge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ls/envs/myenv_x86/lib/python3.8/site-packages/sklearn/gaussian_process/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_gpr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianProcessRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_gpc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianProcessClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkernels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ls/envs/myenv_x86/lib/python3.8/site-packages/sklearn/gaussian_process/_gpc.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_check_optimize_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOneVsOneClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ls/envs/myenv_x86/lib/python3.8/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiOutputMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMetaEstimatorMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_regressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_is_pairwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meuclidean_distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_is_pairwise' from 'sklearn.base' (/Users/krishnayogi/ls/envs/myenv_x86/lib/python3.8/site-packages/sklearn/base.py)"
     ]
    }
   ],
   "source": [
    "#!conda install -c conda-forge skl2onnx -y\n",
    "\n",
    "\n",
    "import onnx\n",
    "import numpy\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "#from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from onnxruntime import InferenceSession\n",
    "from skl2onnx import convert_sklearn, to_onnx, wrap_as_onnx_mixin\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx.algebra.onnx_ops import OnnxSub, OnnxDiv\n",
    "from skl2onnx.algebra.onnx_operator_mixin import OnnxOperatorMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "#loaded_model = pickle.load(open(filename, 'rb'))\n",
    "#result = loaded_model.score(X_test, Y_test)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Packaging Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pickle file or onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.gaussian_process'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_x/15zkvlz965jbcyj2tvmx0ww80000gn/T/ipykernel_30147/940481835.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert into SVC model into ONNX format file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskl2onnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_sklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskl2onnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_types\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFloatTensorType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minitial_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float_input'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloatTensorType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0monx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_sklearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ls/envs/myenv_x86/lib/python3.8/site-packages/skl2onnx/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_sklearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_onnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap_as_onnx_mixin\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m from ._supported_operators import (  # noqa\n\u001b[1;32m     17\u001b[0m     \u001b[0mupdate_registered_converter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_model_alias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ls/envs/myenv_x86/lib/python3.8/site-packages/skl2onnx/convert.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_topology\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_topology\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils_sklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_process_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_parse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_sklearn_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Invoke the registration of all our converters and shape calculators.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ls/envs/myenv_x86/lib/python3.8/site-packages/skl2onnx/_parse.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m from sklearn.ensemble import (\n\u001b[1;32m     17\u001b[0m     IsolationForest, RandomTreesEmbedding, RandomForestClassifier)\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_process\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianProcessRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBayesianRidge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.gaussian_process'"
     ]
    }
   ],
   "source": [
    "# Convert into SVC model into ONNX format file\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "initial_type = [('float_input', FloatTensorType([None, 6]))]\n",
    "onx = convert_sklearn(svc, initial_types=initial_type)\n",
    "with open(\"outputs/svc.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into RF model into ONNX format file\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "initial_type = [('float_input', FloatTensorType([None, 6]))]\n",
    "onx = convert_sklearn(rf, initial_types=initial_type)\n",
    "with open(\"outputs/rf.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Registering Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model support-vector-classifier\n",
      "Name: support-vector-classifier\n",
      "Version: 1\n"
     ]
    }
   ],
   "source": [
    "# Register Model on AzureML WS\n",
    "model = Model.register(model_path = './outputs/svc.pkl', # this points to a local file  # svc.onnx normally\n",
    "                       model_name = \"support-vector-classifier\", # this is the name the model is registered as\n",
    "                       tags = {'dataset': dataset.name, 'version': dataset.version, 'hyparameter-C': '1', 'testdata-accuracy': '0.9519'}, \n",
    "                       model_framework='pandas==0.23.4',\n",
    "                       description = \"Support vector classifier to predict weather at port of Turku\",\n",
    "                       workspace = workspace)\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model random-forest-classifier\n",
      "Name: random-forest-classifier\n",
      "Version: 1\n"
     ]
    }
   ],
   "source": [
    "# Register Model on AzureML WS\n",
    "model = Model.register(model_path = './outputs/rf.pkl', # this points to a local file  # rf.onnx normally\n",
    "                       model_name = \"random-forest-classifier\", # this is the name the model is registered as\n",
    "                       tags = {'dataset': dataset.name, 'version': dataset.version, 'hyparameter-C': '1', 'testdata-accuracy': '0.9548'}, \n",
    "                       model_framework='pandas==0.23.4',\n",
    "                       description = \"Random forest classifier to predict weather at port of Turku\",\n",
    "                       workspace = workspace)\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/17 19:00:27 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /var/folders/_x/15zkvlz965jbcyj2tvmx0ww80000gn/T/tmpqngco8sc/model/model.pkl, flavor: sklearn), fall back to return ['scikit-learn==0.24.2', 'cloudpickle==2.2.0']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x7fc580d385b0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to the outputs directory for capture\n",
    "#mlflow.sklearn.log_model(svc, 'outputs/svc.onnx')\n",
    "\n",
    "mlflow.sklearn.log_model(svc, 'outputs/svc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/17 19:00:50 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /var/folders/_x/15zkvlz965jbcyj2tvmx0ww80000gn/T/tmpa7_74opb/model/model.pkl, flavor: sklearn), fall back to return ['scikit-learn==0.24.2', 'cloudpickle==2.2.0']. Set logging level to DEBUG to see the full traceback.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x7fc5b81f43d0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to the outputs directory for capture\n",
    "#mlflow.sklearn.log_model(rf, 'outputs/rf.onnx')\n",
    "mlflow.sklearn.log_model(rf, 'outputs/rf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model artefacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./outputs/scaler.pkl', 'wb') as scaler_pkl:\n",
    "    pickle.dump(sc, scaler_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Model on AzureML WS\n",
    "scaler = Model.register(model_path = './outputs/scaler.pkl', # this points to a local file \n",
    "                       model_name = \"scaler\", # this is the name the model is registered as\n",
    "                       tags = {'dataset': dataset.name, 'version': dataset.version}, \n",
    "                       model_framework='pandas==0.23.4',\n",
    "                       description = \"Scaler used for scaling incoming inference data\",\n",
    "                       workspace = workspace)\n",
    "\n",
    "print('Name:', scaler.name)\n",
    "print('Version:', scaler.version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv_x86] *",
   "language": "python",
   "name": "conda-env-myenv_x86-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
